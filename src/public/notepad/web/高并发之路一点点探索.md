[toc]

# 序

为什么突然想到了解一下高并发之路呢

因为 2022 年 9 月 2 号成都全民核酸时因核酸系统崩溃导致我白白站了两个多小时

参考文章
[因为核酸系统崩溃，这家公司被骂上了热搜第一](https://mp.weixin.qq.com/s/UKaBXbVln4Zz1UcPHoS3gQ)

# 到底该怎么做高并发

## 1. 单机时代

一开始的时候，用户量很少，一天就几百上千个请求，一台服务器就完全足够。
我们用 Java、Python、PHP 或者其他后端语言开发一个 Web 后端服务，再用一个 MySQL 来存储业务数据，它俩携手工作，运行在同一台服务器上，对外提供服务。

## 2. 应用与数据库分离

慢慢的，用户量开始多了起来，一台服务器有点够呛，把它们拆开成两台服务器，一台专门运行 Web 服务，一台专门用来运行数据库，这样它们就能独享服务器上的 CPU 和内存资源，不用互抢了。

## 3. 缓存系统

后来，用户量进一步增加，每一次都要去数据库里查，有点费时间，引入一个缓存系统，可以有效缩短服务的响应时间。

## 4. 软件负载均衡

用户量还在增加，一个 Web 服务的吞吐量开始达到了上限，系统开始出现卡顿。这时候，可以复制多个 Web 服务出来，再用一个 nginx 来进行负载均衡，将请求分摊到所有 Web 服务器上，提高并发量。

## 5. 数据读写分离

随着系统的运行和用户的增长，数据量越来越多，数据库的瓶颈开始显现，读写明显变慢。这时候，可以增加新的数据库服务器，将读写进行分离，二者做好数据同步，提高数据库服务的整体 I/O 性能。

## 6. 数据库分库分表

系统中的数据越来越多，即便是读写分离了，但一张表中的记录越来越多，从几百万到几千万，甚至要过亿了。把它们全部塞在同一张表里，检索查询耗时费力，是时候进行分库分表，把数据拆分一下，提高数据查询效率。

## 7. 硬件负载均衡

再后来，业务发展很不错，用户量激增，以至于强劲的 Nginx 也扛不住了。
一台不够，那就多整几台，再引入一个硬件负载均衡的服务器，比如 F5，将网络流量分发到不同的 Nginx 服务器上，再一次提高性能。

## 8. DNS 负载均衡

再再后来，用户量还在蹭蹭蹭的增长，强悍如 F5 这样的硬件负载均衡服务器也扛不住这样的高并发。
老办法，一个不够那就多整几个。这一次，咱们在域名解析上下功夫，不同地区的用户，在访问同一个域名时，解析到不同的 IP 地址，以此来将流量进一步拆分。
